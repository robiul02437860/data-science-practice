{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'SMSSpamCollection'\n",
    "sms_df = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'message'])\n",
    "sms_df['type'] = np.where(sms_df[\"label\"]=='ham',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets (70% training, 30% testing)\n",
    "features = sms_df[\"message\"]\n",
    "target = sms_df[\"type\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to TF-IDF features\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Multinomial Naive Bayes model\n",
    "alp = 0.1\n",
    "mnb = MultinomialNB(alpha=alp)\n",
    "\n",
    "# Train the model\n",
    "mnb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Using Fitted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred_idf = mnb.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_idf)\n",
    "class_report = classification_report(y_test, y_pred_idf)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_idf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix (TF-IDF)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, mnb.predict_proba(X_test_tfidf)[:, 1])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=recall_vals, y=precision_vals)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, mnb.predict_proba(X_test_tfidf)[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=fpr, y=tpr, label='AUC = {:.2f}'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Gain/Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precision and recall values\n",
    "precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, mnb.predict_proba(X_test_tfidf)[:, 1])\n",
    "\n",
    "# Calculate cumulative gain\n",
    "cumulative_gain = np.cumsum(precision_vals) / np.sum(y_test)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.arange(len(cumulative_gain)), cumulative_gain, label='Cumulative Gain', color='blue')\n",
    "plt.axhline(y=np.sum(y_test) / len(y_test), color='red', linestyle='--', label='Random Guessing')\n",
    "plt.xlabel('Number of Samples')\n",
    "plt.ylabel('Cumulative Gain')\n",
    "plt.title('Cumulative Gain Chart')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall trade-off\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precision_vals[:-1], label='Precision', color='blue')\n",
    "plt.plot(thresholds, recall_vals[:-1], label='Recall', color='orange')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper Analysis of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts of Spam vs Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of spam to ham\n",
    "sms_spam = sms_df[sms_df.label == \"spam\"]\n",
    "sms_ham = sms_df[sms_df.label == \"ham\"]\n",
    "\n",
    "count_spam = sms_spam.shape[0]\n",
    "count_ham = sms_ham.shape[0]\n",
    "ratio_spam = count_spam / (count_spam + count_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count plot of spam to ham\n",
    "sns.countplot(sms_df, x=\"label\")\n",
    "plt.title(\"Count of Spam and Ham labels\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Percent Spam: {ratio_spam*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Words in Spam vs Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Get the log probabilities of the features\n",
    "log_probs = mnb.feature_log_prob_\n",
    "\n",
    "# Create a DataFrame for the words and their probabilities\n",
    "spam_words = pd.DataFrame({\n",
    "    'Word': feature_names,\n",
    "    'Spam Probability': log_probs[1],\n",
    "    'Ham Probability': log_probs[0]\n",
    "})\n",
    "\n",
    "# Calculate the difference\n",
    "spam_words['Difference'] = spam_words['Spam Probability'] - spam_words['Ham Probability']\n",
    "\n",
    "# Get the top words for spam\n",
    "top_spam_words = spam_words.nlargest(20, 'Difference')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Difference', y='Word', data=top_spam_words, palette='Reds', hue=\"Word\", legend=False)\n",
    "plt.title('Top Words Indicating Spam')\n",
    "plt.xlabel('Log Probability Difference (Spam - Ham)')\n",
    "plt.ylabel('Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud for Spam Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter spam messages\n",
    "spam_messages = sms_df[sms_df['type'] == 1]['message']\n",
    "\n",
    "# Create a single string of all spam messages\n",
    "spam_text = ' '.join(spam_messages)\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(spam_text)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Spam Messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Message Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate message lengths\n",
    "sms_df['length'] = sms_df['message'].apply(len)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=sms_df, x='length', hue='label', multiple='stack', bins=30, kde=True)\n",
    "plt.title('Distribution of Message Lengths')\n",
    "plt.xlabel('Length of Message')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot of Message Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='label', y='length', data=sms_df)\n",
    "plt.title('Box Plot of Message Lengths by Type')\n",
    "plt.xlabel('Message Type')\n",
    "plt.ylabel('Length of Message')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of Word Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer to get word counts with a limit on max features\n",
    "count_vectorizer = CountVectorizer(max_features=50)  # Adjust max_features as needed\n",
    "count_data = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Calculate the correlation matrix directly from the sparse matrix\n",
    "correlation_matrix = (count_data.T @ count_data).toarray()  # Using matrix multiplication\n",
    "correlation_matrix = np.corrcoef(correlation_matrix)  # Calculate correlation coefficients\n",
    "\n",
    "# Create a DataFrame for the correlation matrix\n",
    "correlation_df = pd.DataFrame(correlation_matrix, index=count_vectorizer.get_feature_names_out(), columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_df, cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Word Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Get the log probabilities of the features\n",
    "log_probs = mnb.feature_log_prob_\n",
    "\n",
    "# Create a DataFrame for the words and their probabilities\n",
    "spam_words = pd.DataFrame({\n",
    "    'Word': feature_names,\n",
    "    'Spam Probability': log_probs[1],\n",
    "    'Ham Probability': log_probs[0]\n",
    "})\n",
    "\n",
    "# Calculate the difference\n",
    "spam_words['Difference'] = spam_words['Spam Probability'] - spam_words['Ham Probability']\n",
    "\n",
    "# Get the top words for spam\n",
    "top_spam_words = spam_words.nlargest(20, 'Difference')\n",
    "top_ham_words = spam_words.nsmallest(20, 'Difference')\n",
    "\n",
    "# Combine the two DataFrames\n",
    "top_features = pd.concat([top_ham_words, top_spam_words])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Difference', y='Word', data=top_features, palette='coolwarm', hue=\"Word\", legend=False)\n",
    "plt.title('Top Words Indicating Spam and Ham')\n",
    "plt.xlabel('Log Probability Difference (Spam - Ham)')\n",
    "plt.ylabel('Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities\n",
    "predicted_probabilities = mnb.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Create a DataFrame for the predicted probabilities and actual labels\n",
    "probability_df = pd.DataFrame({'Predicted Probability': predicted_probabilities, 'Actual': y_test})\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=probability_df, x='Predicted Probability', hue='Actual', multiple='stack', bins=30, kde=True)\n",
    "plt.title('Distribution of Predicted Probabilities')\n",
    "plt.xlabel('Predicted Probability of Spam')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
